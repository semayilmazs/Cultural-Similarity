{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3544e6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: c:\\Users\\LENOVO\\Desktop\\Cultural Similarity\\Cultural-Similarity\n",
      "KEYWORDS_JSON exists: True\n",
      "OUT_CSV: c:\\Users\\LENOVO\\Desktop\\Cultural Similarity\\Cultural-Similarity\\data\\processed\\smoke_test.csv\n"
     ]
    }
   ],
   "source": [
    "import json, time, random\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "from pytrends.exceptions import TooManyRequestsError\n",
    "\n",
    "# 1) Project root'u sabitle\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if (PROJECT_ROOT / \"keywords_FINAL_2025.json\").exists() is False and PROJECT_ROOT.name.lower() == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "KEYWORDS_JSON = PROJECT_ROOT / \"keywords_FINAL_2025.json\"\n",
    "\n",
    "# 2) Output klasörleri\n",
    "OUT_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_CSV = OUT_DIR / \"smoke_test.csv\"\n",
    "ERR_CSV = OUT_DIR / \"smoke_test_errors.csv\"\n",
    "\n",
    "# 3) Smoke test parametreleri (429 azaltmak için)\n",
    "COUNTRIES = [\"PL\", \"TR\", \"BR\"]   # sonra artırırsın\n",
    "TIMEFRAME = \"today 3-m\"         # 12-m yerine 3-m (test için ideal)\n",
    "BASE_SLEEP = 6                  # her istek arası minimum bekleme\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"KEYWORDS_JSON exists:\", KEYWORDS_JSON.exists())\n",
    "print(\"OUT_CSV:\", OUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90083d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected topics:\n",
      "- Inflation /m/09jx2\n",
      "- Cost of Living /m/01fss9\n",
      "- Price Hike /g/11mcmf67yl\n",
      "- Shrinkflation /m/010w1kk1\n"
     ]
    }
   ],
   "source": [
    "with open(KEYWORDS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "def get_group_queries(cfg, category_name, group_name):\n",
    "    for cat in cfg.get(\"categories\", []):\n",
    "        if cat.get(\"category_name\") == category_name:\n",
    "            for grp in cat.get(\"sub_groups\", []):\n",
    "                if grp.get(\"group_name\") == group_name:\n",
    "                    return grp.get(\"queries\", [])\n",
    "    return []\n",
    "\n",
    "queries = get_group_queries(cfg, \"FINANCE\", \"Inflation\")\n",
    "if not queries:\n",
    "    raise ValueError(\"FINANCE -> Inflation bulunamadı. JSON içindeki isimleri kontrol et.\")\n",
    "\n",
    "topics = [(q[\"label\"], q[\"topic_id\"]) for q in queries]\n",
    "\n",
    "# Smoke testte maksimum 4 topic ile kalalım\n",
    "topics = topics[:4]\n",
    "\n",
    "print(\"Selected topics:\")\n",
    "for label, tid in topics:\n",
    "    print(\"-\", label, tid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f29081",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrends = TrendReq(hl=\"en-US\", tz=180)\n",
    "\n",
    "def fetch_interest_over_time(topic_ids, geo, timeframe):\n",
    "    pytrends.build_payload(\n",
    "        kw_list=topic_ids,\n",
    "        cat=0,\n",
    "        timeframe=timeframe,\n",
    "        geo=geo,\n",
    "        gprop=\"\"\n",
    "    )\n",
    "    return pytrends.interest_over_time()\n",
    "\n",
    "def fetch_with_retry(topic_ids, geo, timeframe, max_retries=6, base_sleep=8):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return fetch_interest_over_time(topic_ids, geo=geo, timeframe=timeframe)\n",
    "        except TooManyRequestsError:\n",
    "            wait = base_sleep * (2 ** attempt) + random.uniform(0, 2.0)\n",
    "            print(f\"[429] geo={geo} retry {attempt+1}/{max_retries} -> sleep {wait:.1f}s\")\n",
    "            time.sleep(wait)\n",
    "    raise TooManyRequestsError(f\"Max retries exceeded for geo={geo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664ed178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded: 8\n"
     ]
    }
   ],
   "source": [
    "seen = set()\n",
    "if OUT_CSV.exists():\n",
    "    old = pd.read_csv(OUT_CSV)\n",
    "    # (geo, topic_id, timeframe) olarak işaretle\n",
    "    if set([\"geo\",\"topic_id\",\"timeframe\"]).issubset(old.columns):\n",
    "        seen = set(zip(old[\"geo\"], old[\"topic_id\"], old[\"timeframe\"]))\n",
    "        print(\"Checkpoint loaded:\", len(seen))\n",
    "    else:\n",
    "        print(\"OUT_CSV var ama kolonlar beklenenden farklı. Skip checkpoint.\")\n",
    "else:\n",
    "    print(\"No checkpoint yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95a88d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\LENOVO\\Desktop\\Cultural Similarity\\Cultural-Similarity\\data\\processed\\smoke_test.csv\n",
      "Saved: c:\\Users\\LENOVO\\Desktop\\Cultural Similarity\\Cultural-Similarity\\data\\processed\\smoke_test_errors.csv\n"
     ]
    }
   ],
   "source": [
    "out_csv = OUT_DIR / \"smoke_test.csv\"\n",
    "err_csv = OUT_DIR / \"smoke_test_errors.csv\"\n",
    "\n",
    "result.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "err_df.to_csv(err_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", out_csv)\n",
    "print(\"Saved:\", err_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d9c122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GEO: PL ===\n",
      "Missing: ['Inflation', 'Cost of Living', 'Price Hike', 'Shrinkflation']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytrends\\request.py:266: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rows so far: 792\n",
      "\n",
      "=== GEO: TR ===\n",
      "Missing: ['Inflation', 'Cost of Living', 'Price Hike', 'Shrinkflation']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytrends\\request.py:266: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rows so far: 1160\n",
      "\n",
      "=== GEO: BR ===\n",
      "Missing: ['Inflation', 'Cost of Living', 'Price Hike', 'Shrinkflation']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytrends\\request.py:266: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rows so far: 1528\n",
      "\n",
      "DONE\n",
      "OUT: c:\\Users\\LENOVO\\Desktop\\Cultural Similarity\\Cultural-Similarity\\data\\processed\\smoke_test.csv exists: True\n",
      "ERR: c:\\Users\\LENOVO\\Desktop\\Cultural Similarity\\Cultural-Similarity\\data\\processed\\smoke_test_errors.csv exists: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>interest</th>\n",
       "      <th>label</th>\n",
       "      <th>geo</th>\n",
       "      <th>timeframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>/m/09jx2</td>\n",
       "      <td>55</td>\n",
       "      <td>Inflation</td>\n",
       "      <td>PL</td>\n",
       "      <td>today 12-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-22</td>\n",
       "      <td>/m/09jx2</td>\n",
       "      <td>43</td>\n",
       "      <td>Inflation</td>\n",
       "      <td>PL</td>\n",
       "      <td>today 12-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>/m/09jx2</td>\n",
       "      <td>73</td>\n",
       "      <td>Inflation</td>\n",
       "      <td>PL</td>\n",
       "      <td>today 12-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>/m/09jx2</td>\n",
       "      <td>81</td>\n",
       "      <td>Inflation</td>\n",
       "      <td>PL</td>\n",
       "      <td>today 12-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-12</td>\n",
       "      <td>/m/09jx2</td>\n",
       "      <td>100</td>\n",
       "      <td>Inflation</td>\n",
       "      <td>PL</td>\n",
       "      <td>today 12-m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  topic_id  interest      label geo   timeframe\n",
       "0  2024-12-15  /m/09jx2        55  Inflation  PL  today 12-m\n",
       "1  2024-12-22  /m/09jx2        43  Inflation  PL  today 12-m\n",
       "2  2024-12-29  /m/09jx2        73  Inflation  PL  today 12-m\n",
       "3  2025-01-05  /m/09jx2        81  Inflation  PL  today 12-m\n",
       "4  2025-01-12  /m/09jx2       100  Inflation  PL  today 12-m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "records = []\n",
    "errors = []\n",
    "\n",
    "# existing output varsa yeni kayıtları ona ekleyeceğiz\n",
    "existing = pd.read_csv(OUT_CSV) if OUT_CSV.exists() else pd.DataFrame()\n",
    "\n",
    "id_to_label = {tid: lbl for (lbl, tid) in topics}\n",
    "\n",
    "for geo in COUNTRIES:\n",
    "    # Bu geo için eksik topic'leri bul\n",
    "    missing_ids = [tid for (lbl, tid) in topics if (geo, tid, TIMEFRAME) not in seen]\n",
    "    missing_labels = [id_to_label[tid] for tid in missing_ids]\n",
    "\n",
    "    print(f\"\\n=== GEO: {geo} ===\")\n",
    "    print(\"Missing:\", missing_labels)\n",
    "\n",
    "    if not missing_ids:\n",
    "        print(\"Nothing to fetch. (Already collected)\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = fetch_with_retry(missing_ids, geo=geo, timeframe=TIMEFRAME)\n",
    "\n",
    "        if df is None or df.empty:\n",
    "            errors.append({\"geo\": geo, \"batch\": missing_labels, \"error\": \"Empty dataframe\"})\n",
    "        else:\n",
    "            if \"isPartial\" in df.columns:\n",
    "                df = df.drop(columns=[\"isPartial\"])\n",
    "\n",
    "            df_long = (\n",
    "                df.reset_index()\n",
    "                .melt(id_vars=[\"date\"], var_name=\"topic_id\", value_name=\"interest\")\n",
    "            )\n",
    "            df_long[\"label\"] = df_long[\"topic_id\"].map(id_to_label)\n",
    "            df_long[\"geo\"] = geo\n",
    "            df_long[\"timeframe\"] = TIMEFRAME\n",
    "\n",
    "            # Append + save immediately (crash-proof)\n",
    "            combined = pd.concat([existing, df_long], ignore_index=True)\n",
    "            combined.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "            existing = combined\n",
    "\n",
    "            # Update seen\n",
    "            for tid in missing_ids:\n",
    "                seen.add((geo, tid, TIMEFRAME))\n",
    "\n",
    "            print(f\"Saved rows so far: {len(existing)}\")\n",
    "\n",
    "        # normal sleep (429 olmasa da)\n",
    "        time.sleep(BASE_SLEEP + random.uniform(0, 1.5))\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append({\"geo\": geo, \"batch\": missing_labels, \"error\": repr(e)})\n",
    "        pd.DataFrame(errors).to_csv(ERR_CSV, index=False, encoding=\"utf-8\")\n",
    "        print(\"Error saved:\", repr(e))\n",
    "        time.sleep(BASE_SLEEP + random.uniform(0, 1.5))\n",
    "\n",
    "# Save errors (if any)\n",
    "err_df = pd.DataFrame(errors)\n",
    "err_df.to_csv(ERR_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nDONE\")\n",
    "print(\"OUT:\", OUT_CSV, \"exists:\", OUT_CSV.exists())\n",
    "print(\"ERR:\", ERR_CSV, \"exists:\", ERR_CSV.exists())\n",
    "display(existing.head())\n",
    "display(err_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
